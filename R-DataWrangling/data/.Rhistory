accuracy
plot(cutoff, accuracy)
# Model 4 - Try different cut offs
cutoff <- seq(50,70)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'Male','Female') %>% factor (levels=levels(test_set$sex))
mean (y_hat == test_set$sex)
})
plot(cutoff, accuracy)
# Model 4 - Try different cut offs
cutoff <- seq(60,70)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'Male','Female') %>% factor (levels=levels(test_set$sex))
mean (y_hat == test_set$sex)
})
plot(cutoff, accuracy)
#Final model - using best cutoff
best_cutoff <- 61
y_hat <- ifelse(train_set$height > best_cutoff, 'Male','Female') %>% factor (levels=levels(test_set$sex))
y_hat
mean (y_hat == test_set$sex) ##Accuracy drops to 62%
###############MNIST Dataset
read_mnist()
###############MNIST Dataset
mnist <- read_mnist()
mnist
class (mnist)
length(mnist)
mnist[1]
mnist[2]
mnist[1]
mnist[1]$train
mnist[1]$train$labels
mnist[1]$train$labels
class (mnist[1]$train$labels)
mnist[1]$train$labels
unique(mnist[1]$train$labels)
length(unique(mnist[1]$train$labels))
labels <- mnist[1]$train$labels
length(unique(labels))
images <- mnist[1]$train$images[1]
images
images <- mnist[1]$train$images
images
images
class (images)
dim(images)
#Confusion Matrix
table(predicted = y_hat, actual = test_set$sex)
#find mean of males
mean (heights$sex=='Male')
mean (heights$sex=='Female')
confusionMatrix(data=y_hat, reference = test_set$sex)
F_meas(data=y_hat, reference = factor(test_set$sex))
# Model 5 - Try different cut offs and measure F1
cutoff <- seq(60,70)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
})
plot(cutoff, F_1) #best accuracy is around 61
new_best_cutoff <- 69
y_hat <- ifelse(train_set$height > new_best_cutoff, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
# Model 5 - Try different cut offs and measure F1
cutoff <- seq(60,75)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
})
plot(cutoff, F_1) #best f1_score is around 69
confusionMatrix(data=y_hat, reference = test_set$sex)
best_cutoff <- cutoff[which.max(F_1)]
best_cutoff
new_best_cutoff <- cutoff[which.max(F_1)]
new_best_cutoff
y_hat <- ifelse(train_set$height > new_best_cutoff, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
confusionMatrix(data=y_hat, reference = test_set$sex)
confusionMatrix(data=y_hat, reference = test_set$sex)
confusionMatrix(data=y_hat, reference = test_set$sex)
library(dslabs)
library(dplyr)
library(lubridate)
data(reported_heights)
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type
dat$type
dat %>% filter(type=='inclass') %>% count())
dat %>% filter(type=='inclass') %>% count()
dat %>% filter(type=='inclass' & sex='Female') %>% count()
dat %>% filter(type=='inclass' & sex=='Female') %>% count()
inclass_students<-dat %>% filter(type=='inclass') %>% count()
inclass_fml_students<-dat %>% filter(type=='inclass' & sex=='Female') %>% count()
inclass_fml_students/inclass_students
x
e
e
online_students<-dat %>% filter(type=='online') %>% count()
online_fml_students<-dat %>% filter(type=='online' & sex=='Female') %>% count()
online_fml_students/online_students
p=0.6666
sample(c('Male','Female'), dat$sex, p=c(p,1-p), replace = TRUE)
sample(c('Male','Female'), length(dat$sex), p=c(p,1-p), replace = TRUE)
mean (guessed_sex==dat$sex)
guessed_sex <- sample(c('Male','Female'), length(dat$sex), p=c(p,1-p), replace = TRUE)
mean (guessed_sex==dat$sex)
y_hat <- ifelse(x == "online", "Male", "Female") %>% factor(levels = levels(y))
mean (y_hat==dat$sex)
y_hat <- ifelse(x == "inclass", "Female", "Male") %>% factor(levels = levels(y))
mean (y_hat==dat$sex)
#Write a line of code using the table() function to show the confusion matrix between y_hat and y. Use the exact format function(a, b) for your answer and do not name the columns and rows.
table(y_hat, test_set$sex) #reveals problem with model
table(y_hat, dat$sex)
#Write a line of code using the table() function to show the confusion matrix between y_hat and y. Use the exact format function(a, b) for your answer and do not name the columns and rows.
table(y_hat, y) #reveals problem with model
#What is the sensitivity of this prediction? You can use the sensitivity() function from the caret package. Enter your answer as a percentage or decimal (eg "50%" or "0.50") to at least the hundredths place.
confusionMatrix(data=y_hat, reference = y)
library(caret)
data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
y <- iris$Species
y
unique(y)
unique(y)
iris$Species
unique(iris$Species)
class(iris$Species)
factor(iris$Species)
count (iris, 'Species')
library(dplyr)
count (iris, 'Species')
class(y)
factor(y)
count (factor(y))
summarise(y)
table(y)
class(y)
factor(y)
table(y)
set.seed(2)    # if using R 3.6 or later, use set.seed(2, sample.kind="Rounding")
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
#Split train and test
set.seed(2)    # if using R 3.6 or later, use set.seed(2, sample.kind="Rounding")
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
mean (iris$Sepal.Length)
mean (iris$Sepal.Length)
mean (iris$Sepal.Length)
mean (iris$Sepal.Width)
mean (iris$Petal.Length)
mean (iris$Petal.Width)
find_best_feature(seq(6.0,6.5,by = 0.1))
find_best_feature <- function(cutoff){
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(train_set$height > new_best_cutoff, 'Male','Female') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
}
find_best_feature(seq(6.0,6.5,by = 0.1))
table(y)
find_best_feature <- function(cutoff){
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train_set$height > x, 'virginica','versicolo') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(train_set$height > new_best_cutoff, 'virginica','versicolo') %>% factor (levels=levels(test_set$sex))
F_meas(data=y_hat, reference = factor(test_set$sex))
}
find_best_feature(seq(6.0,6.5,by = 0.1))
find_best_feature <- function(feature,cutoff){
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$feature > x, 'virginica','versicolo') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(iris$feature > new_best_cutoff, 'virginica','versicolo') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
}
find_best_feature('Sepal.Length',seq(6.0,6.5,by = 0.1))
find_best_feature <- function(feature,cutoff){
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$feature > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(iris$feature > new_best_cutoff, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
}
find_best_feature('Sepal.Length',seq(6.0,6.5,by = 0.1))
factor(y)
table(y)
find_best_feature <- function(feature,cutoff){
print (iris$feature)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$feature > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(iris$feature > new_best_cutoff, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
}
find_best_feature('Sepal.Length',seq(6.0,6.5,by = 0.1))
find_best_feature <- function(feature,cutoff){
print (iris$Sepal.Length)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$feature > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(iris$feature > new_best_cutoff, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
}
find_best_feature('Sepal.Length',seq(6.0,6.5,by = 0.1))
find_best_feature <- function(feature,cutoff){
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
new_best_cutoff <- cutoff[which.max(F_1)]
y_hat <- ifelse(iris$Sepal.Length > new_best_cutoff, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
}
find_best_feature('Sepal.Length',seq(6.0,6.5,by = 0.1))
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
cutoff <- seq(6.0,6.5,by = 0.1)
cutoff <- seq(6.0,6.5,by = 0.1)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor') %>% factor (levels=levels(y))
F_meas(data=y_hat, reference = factor(y))
})
# Model 1 - Try different values of each feature and measure F1
table(train$Species)
cutoff <- seq(6.0,6.5,by = 0.1)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor')
F_meas(data=y_hat, reference = factor(y))
})
cutoff <- seq(6.0,6.5,by = 0.1)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor')
F_meas(data=y_hat, reference = factor(train$Species))
})
mean (y_hat == train$Species)
cutoff <- seq(6.0,6.5,by = 0.1)
F_1 <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
find_best_feature <- function(cutoff){
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(iris$Sepal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(iris$Sepal.Length > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(seq(6.0,6.5,by = 0.1))
iris$0
iris[0]
iris[1]
iris[2]
find_best_feature <- function(col,cutoff){
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(iris[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(iris[y] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(0,seq(6.0,6.5,by = 0.1))
cutoff <- seq(6.0,6.5,by = 0.1)
col <-1
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(iris[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(iris[y] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
find_best_feature(1,seq(6.0,6.5,by = 0.1))
mean (iris$Sepal.Length)
mean (iris$Sepal.Width)
mean (iris$Petal.Length)
mean (iris$Petal.Width)
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature(2,seq(2.5,3.0,by = 0.1))
find_best_feature(3,seq(4.5,5.0,by = 0.1))
find_best_feature(4,seq(1.4,1.9,by = 0.1))
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature(2,seq(2.5,3.0,by = 0.1))
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature(2,seq(2.5,3.0,by = 0.1))
train[1]
train[2]
train[3]
train[4]
cutoff <- seq(2.5,3.0,by = 0.1)
col <- 2
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
rlang::last_error()
find_best_feature <- function(col,cutoff){
cutoff <- seq(2.5,3.0,by = 0.1)
col <- 2
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[1] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(train[1] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature <- function(col,cutoff){
cutoff <- seq(2.5,3.0,by = 0.1)
col <- 2
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(train[y] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature(1,seq(6.0,6.5,by = 0.1))
function (cnd)
{
if (is_true(peek_option("rlang_force_unhandled_error"))) {
fallback <- cnd
}
else {
signalCondition(cnd)
fallback <- cnd("rlang_error")
}
last_error_env$cnd <- cnd
fallback$message <- paste_line(conditionMessage(cnd), format_onerror_backtrace(cnd))
stop(fallback)
}
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature(1,seq(6.0,6.5,by = 0.1))
find_best_feature <- function(col,cutoff){
cutoff <- seq(2.5,3.0,by = 0.1)
col <- 2
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(iris[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(iris[y] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(1,seq(6.0,6.5,by = 0.1))
train[1]
train[1] > seq(6.0,6.5,by = 0.1)
train[2] > seq(2.5,3.0,by = 0.1)
cutoff <- seq(2.5,3.0,by = 0.1)
col <- 2
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
find_best_feature <- function(col,cutoff){
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train[y] > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(train[y] > new_best_cutoff, 'virginica','versicolor')
print (mean (y_hat == train$Species))
}
find_best_feature(1,seq(6.0,6.5,by = 0.1))
foo <- function(x){
rangedValues <- seq(range(x)[1],range(x)[2],by=0.1)
sapply(rangedValues, function(i){
y_hat <- ifelse(x > i,'virginica','versicolor')
mean(y_hat == train$Species)
})
}
predictions <- apply(train[,-5], 2, foo)
sapply(predictions,max)
mean (iris$Petal.Length)
# Model 1 - Try different values of each feature and measure F1
table(train$Species)
cutoff <- seq(4.4,5.2,by = 0.1)
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
# Model 1 - Try different values of each feature and measure F1
table(train$Species)
cutoff <- seq(4.4,5.2,by = 0.1)
accuracy <- map_dbl(cutoff, col, function (x,y){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(train$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == train$Species)
range(iris$Petal.Length)
cutoff <- seq(range(iris$Petal.Length)[1],range(iris$Petal.Length)[2],by = 0.1)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(train$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == train$Species)
# Model 1 - Try different values of each feature and measure F1
table(train$Species)
cutoff <- seq(range(iris$Petal.Length)[1],range(iris$Petal.Length)[2],by = 0.1)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
print (new_best_cutoff)
y_hat <- ifelse(train$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == train$Species)
cutoff <- seq(range(iris$Petal.Length)[1],range(iris$Petal.Length)[2],by=0.1)[which.max(predictions[["Petal.Length"]])]
accuracy <- iris %>%
mutate(y_hat = ifelse(Petal.Length >= cutoff, 'virginica','versicolor')) %>%
summarize(mean(y_hat == Species))
accuracy
cutoff <- seq(range(iris$Petal.Length)[1],range(iris$Petal.Length)[2],by = 0.1)
print (cutoff)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
accuracy
new_best_cutoff <- cutoff[which.max(accuracy)]
print (new_best_cutoff)
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(test$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == test$Species)
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
mean (iris$Sepal.Length)
mean (iris$Sepal.Width)
mean (iris$Petal.Length)
mean (iris$Petal.Width)
foo <- function(x){
rangedValues <- seq(range(x)[1],range(x)[2],by=0.1)
sapply(rangedValues, function(i){
y_hat <- ifelse(x > i,'virginica','versicolor')
mean(y_hat == train$Species)
})
}
predictions <- apply(train[,-5], 2, foo)
sapply(predictions,max)
# Model 1 - Try different values of each feature and measure accuracy
table(train$Species)
cutoff <- seq(range(train$Petal.Length)[1],range(train$Petal.Length)[2],by = 0.1)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(test$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == test$Species)
predictions <- apply(test[,-5], 2, foo)
sapply(predictions,max)
predictions <- apply(train[,-5], 2, foo)
sapply(predictions,max)
#Which feature best optimizes our overall accuracy?
predictions <- apply(test[,-5], 2, foo)
sapply(predictions,max)
#For the feature selected in Q8, use the smart cutoff value from the training data to calculate overall accuracy in the test data. What is the overall accuracy?
table(train$Species)
cutoff <- seq(range(train$Petal.Length)[1],range(train$Petal.Length)[2],by = 0.1)
accuracy <- map_dbl(cutoff, function (x){
y_hat <- ifelse(train$Petal.Length > x, 'virginica','versicolor')
mean (y_hat == train$Species)
})
new_best_cutoff <- cutoff[which.max(accuracy)]
y_hat <- ifelse(test$Petal.Length > new_best_cutoff, 'virginica','versicolor')
mean (y_hat == test$Species)
Q
Q
